{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b89ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pathlib\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from scipy import interpolate\n",
    "from math import pi\n",
    "from matplotlib import pyplot\n",
    "from math import pi\n",
    "from numpy import nan\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import interpolate\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.stats import rice\n",
    "from scipy.stats import gumbel_r\n",
    "from scipy.stats import genextreme\n",
    "from scipy.stats import genpareto\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "from math import pi\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure\n",
    "from math import pi\n",
    "from numpy import nan\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from numpy import asarray\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta # Date Functions\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error # For measuring model performance / errors\n",
    "from sklearn.preprocessing import MinMaxScaler #to normalize the price data \n",
    "from tensorflow.keras.models import Sequential # Deep learning library, used for neural networks\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv2D, Conv1D, MaxPooling2D # Deep learning classes for recurrent and regular densely-connected layers\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style('white', { 'axes.spines.right': False, 'axes.spines.top': False})\n",
    "# check the tensorflow version and the number of available GPUs\n",
    "print('Tensorflow Version: ' + tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ADT is a one dimetional vehicle yearly volume data. \n",
    "# It one dimetional data with only one colume of timestamp and another column of vehicle volume\n",
    "# First step is to make timestamp column as Index column\n",
    "\n",
    "data_ADT = data[['year1', 'totadt1']].astype(int)\n",
    "data_ADT = data_ADT.set_index('year1')\n",
    "print(data_ADT.head())\n",
    "data_ADT.plot()\n",
    "plt.show()\n",
    "############################################################## LSTM\n",
    "\n",
    "#### Feature Selection - Only Close Data\n",
    "train_df = data_ADT.filter(['totadt1'])\n",
    "# train_df = df\n",
    "# print(train_df)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# train_df = shuffle(train_df)\n",
    "data_unscaled = train_df.values\n",
    "\n",
    "# Get the number of rows to train the model on 80% of the data \n",
    "train_data_length = math.ceil(len(data_unscaled) * 0.7)\n",
    "\n",
    "# Transform features by scaling each feature to a range between 0 and 1\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "np_data = mmscaler.fit_transform(data_unscaled)\n",
    "# print(np_data)\n",
    "\n",
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "\n",
    "sequence_length = 12\n",
    "\n",
    "# Prediction Index\n",
    "index_weight = train_df.columns.get_loc('totadt1')\n",
    "print('Prediction Index: ', index_weight)\n",
    "# Split the training data into train and train data sets\n",
    "# As a first step, we get the number of rows to train the model on 80% of the data \n",
    "train_data_len = math.ceil(np_data.shape[0] * 0.7)\n",
    "\n",
    "# Create the training and test data\n",
    "train_data = np_data[0:train_data_len, :]\n",
    "test_data = np_data[train_data_len - sequence_length:, :]\n",
    "\n",
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(sequence_length, train_df):\n",
    "    x, y = [], []\n",
    "    data_len = train_df.shape[0]\n",
    "    for ij in range(sequence_length, data_len):\n",
    "        x.append(train_df[ij-sequence_length:ij,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "        y.append(train_df[ij, index_weight]) #contains the prediction values for validation (3rd column = Close),  \n",
    "                                             #for single-step prediction\n",
    "\n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Generate training data and test data\n",
    "x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "# print(x_train)\n",
    "x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "# Print the shapes: the result is: (rows, training_sequence, features) | (prediction value, )\n",
    "print('X Train Shape: ', x_train.shape, '| Y Train Shape: ',y_train.shape)\n",
    "print('X Test Shape: ', x_test.shape, '| Y Test Shape: ', y_test.shape)\n",
    "\n",
    "# Validate that the prediction value and the input match up\n",
    "# The last gross weight of the second input sample should equal the first prediction of gross weight value\n",
    "print(x_test[1][sequence_length-1][index_weight])\n",
    "print(y_test[0])\n",
    "\n",
    "# Configure the neural network model\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "epoch = 300\n",
    "batch_size = 8\n",
    "neurons = sequence_length     # Model with sequence_length Neurons \n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, return_sequences=True, dropout=0.0, recurrent_dropout= 0, input_shape=(x_train.shape[1], 1))) \n",
    "model.add(LSTM(neurons, return_sequences=True, dropout=0.0, recurrent_dropout= 0))\n",
    "model.add(LSTM(neurons, return_sequences=False, dropout=0.0, recurrent_dropout= 0))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "# Training the model\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epoch, \n",
    "                    validation_split = 0.2, shuffle=True, verbose= 0, callbacks=[es])\n",
    "epoch_es = len(history.history['val_loss'])\n",
    "print('Early Stop Epoch: ', epoch_es)\n",
    "# Get the predicted values\n",
    "y_pred_scaled = model.predict(x_test)\n",
    "y_pred = mmscaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = mmscaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "MAE = mean_absolute_error(y_test_unscaled, y_pred)\n",
    "print(f'Median Absolute Error (MAE): {np.round(MAE, 2)}')\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %')\n",
    "\n",
    "# Median Absolute Percentage Error (MDAPE)\n",
    "MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled)) ) * 100\n",
    "print(f'Median Absolute Percentage Error (MDAPE): {np.round(MDAPE, 2)} %')\n",
    "\n",
    "# The date from which on the date is displayed\n",
    "# display_start_date = \"2018-01-01\" \n",
    "\n",
    "# Add the difference between the valid and predicted weights\n",
    "train = pd.DataFrame(train_df[:train_data_length + 1]).rename(columns={'totadt1': 'x_train'})\n",
    "valid = pd.DataFrame(train_df[train_data_length:]).rename(columns={'totadt1': 'y_test'})\n",
    "# print(valid)\n",
    "valid.insert(1, \"y_pred\", y_pred, True)\n",
    "valid.insert(1, \"residuals\", valid[\"y_pred\"] - valid[\"y_test\"], True)\n",
    "df_union = pd.concat([train, valid])\n",
    "# print(df_union)\n",
    "rmse = np.sqrt(mean_squared_error(valid[\"y_pred\"], valid[\"y_test\"]))\n",
    "print('RMSE:', str(rmse))\n",
    "\n",
    "\n",
    "############### LSTM outcomes visualizations\n",
    "# Zoom in to a closer timeframe\n",
    "df_union_zoom = df_union\n",
    "#         print(df_union_zoom)\n",
    "\n",
    "# Create the lineplot\n",
    "fig, ax = plt.subplots(figsize=(16, 5), sharex=True)\n",
    "# plt.title(\"Weight Prediction vs Actual Weights (kips)(Epoch \"+str(epoch_es)+\")(Site ID \"+str(SITE_ID)+\")(\"+str(BOUND[i])+\")\", fontsize=14)\n",
    "plt.ylabel('ADT')\n",
    "plt.xlabel('Year')\n",
    "sns.lineplot(data=df_union_zoom[\"x_train\"], linewidth=1.0, linestyle = 'solid', color = 'gray')\n",
    "sns.lineplot(data=df_union_zoom[\"y_test\"], linewidth=1.0, linestyle = 'solid', color = 'black')\n",
    "sns.lineplot(data=df_union_zoom[\"y_pred\"], linewidth=1.0, linestyle = 'dashed', color = 'black')\n",
    "sns.lineplot(data=df_union_zoom[\"residuals\"], linewidth=1.0, linestyle = 'dotted', color = 'black')\n",
    "plt.legend([\"Training Data\", \"Test Data\", \"Test Prediction\", \"Residuals\"], loc=\"best\")\n",
    "# plt.fill_between(data_ADT.index, under_line, over_line, color='black', alpha=.1)\n",
    "plt.grid(axis = 'x')\n",
    "# plt.savefig(new_path +'\\\\' + new_folder +'\\\\'+str(BOUND[i])+'~Test_Train_Residual plot (Site ID '+str(SITE_ID)+').png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait',transparent=True,bbox_inches=\"tight\" )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True)\n",
    "# plt.title(\"Test data vs predictions (kips)(Epoch \"+str(epoch_es)+\")(Site ID \"+str(SITE_ID)+\")(\"+str(BOUND[i])+\")\", fontsize=14)\n",
    "plt.ylabel('ADT')\n",
    "plt.xlabel('Year')\n",
    "sns.lineplot(data=valid[\"y_test\"], linewidth=1.0, linestyle = 'solid', color= 'black')\n",
    "sns.lineplot(data=valid[\"y_pred\"], linewidth=1.0, linestyle = 'dashed', color= 'black')\n",
    "plt.legend(['Test Data', 'Test Prediction'], loc='best')\n",
    "plt.grid(axis = 'x')\n",
    "plt.xticks(rotation = 30)\n",
    "#             plt.fill_between(valid.index, under_line, over_line, color='black', alpha=.1)\n",
    "# plt.savefig(new_path +'\\\\' +new_folder +'\\\\'+str(BOUND[i])+'~Train data vs test (Site ID '+str(SITE_ID)+').png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait',transparent=True,bbox_inches=\"tight\" )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'], linestyle = 'solid', color = 'gray')\n",
    "plt.plot(history.history['val_loss'], linestyle = 'solid', color = 'Black')\n",
    "# plt.title('Model Loss (Epoch '+str(epoch_es)+')(Site ID '+str(SITE_ID)+')('+str(BOUND[i])+')', fontsize=14)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Test'], loc='best')\n",
    "# plt.savefig(new_path +'\\\\' +new_folder +'\\\\'+str(BOUND[i])+'~Model Loss vs Epoch Plot (Site ID '+str(SITE_ID)+').png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait',transparent=True,bbox_inches=\"tight\" )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
